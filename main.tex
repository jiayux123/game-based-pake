\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\usepackage{authblk}
\usepackage{cryptocode}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{float}
\usepackage{framed}
\usepackage[colorlinks]{hyperref}
\def\tmp#1#2#3{
  \definecolor{Hy#1color}{#2}{#3}
  \hypersetup{#1color=Hy#1color}}
\tmp{link}{HTML}{800006}
\tmp{cite}{HTML}{2E7E2A} % better default colors for hyperref links; see https://tex.stackexchange.com/a/525297
\usepackage[capitalise]{cleveref}

\newcommand{\group}{\mathbb{G}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\negl}{\mathsf{negl}}

\newcommand{\adv}{\mathcal{A}}
\newcommand{\env}{\mathcal{Z}}
\renewcommand{\sim}{\mathcal{S}}
\newcommand{\red}{\mathcal{R}}
\newcommand{\func}{\mathcal{F}}
\newcommand{\Fpake}{\func_\mathrm{PAKE}}
\newcommand{\Fipake}{\func_\mathrm{iPAKE}}

\newcommand{\Adv}{\mathbf{Adv}}
\newcommand{\Dist}{\mathbf{Dist}}

\newcommand{\ICEnc}{\mathcal{E}}
\newcommand{\ICDec}{\mathcal{D}}

\newcommand{\pw}{\mathsf{pw}}

\newcommand{\NewSession}{\mathsf{NewSession}}
\newcommand{\TestPwd}{\mathsf{TestPwd}}
\newcommand{\NewKey}{\mathsf{NewKey}}

\newcommand{\fresh}{\mathsf{fresh}}
\newcommand{\compromised}{\mathsf{compromised}}
\newcommand{\interrupted}{\mathsf{interrupted}}
\newcommand{\completed}{\mathsf{completed}}

\newcommand{\Execute}{\mathsf{Execute}}
\newcommand{\Send}{\mathsf{Send}}
\newcommand{\Reveal}{\mathsf{Reveal}}
\newcommand{\Test}{\mathsf{Test}}

\newcommand{\SpuriousGuess}{\mathsf{SpuriousGuess}}
\newcommand{\CorrectGuess}{\mathsf{CorrectGuess}}

\interfootnotelinepenalty=10000 % force footnotes to appear on the same page

\begin{document}

\title{Does the UC-Security Notion for PAKE \\ Imply Game-Based Security?}

\author{Jiayu Xu}
\affil{Oregon State University \\ \texttt{xujiay@oregonstate.edu}}
\date{}

\maketitle

\section{Introduction}
A \emph{Password-Authenticated Key Exchange (PAKE)} protocol allows two parties to jointly establish a cryptographically strong key, in the setting where the only information shared in advance is a low-entropy string called the password. Crucially, such a protocol must be secure against man-in-the-middle adversaries that can arbitrarily modify the protocol messages. One common attack on PAKE is \emph{online guessing}, in which the adversary chooses a candidate password $\pw^*$ and impersonates Bob to Alice; if Alice's password is indeed $\pw^*$, then the adversary learns Alice's output key. Since passwords have low entropy, the adversary has a non-negligible probability of guessing Alice's password correctly; at a high level security for PAKE requires that online guessing is the only feasible attack.

While the intuition of PAKE security looks simple and innocuous, a formal security definition proves incredibly difficult. There are two such definitions considered standard by the community: the game-based security notion by Bellare, Pointcheval and Rogaway \cite{EC:BelPoiRog00} (henceforth \emph{BPR-security}), and the Universally Composable (UC) security notion by Canetti et al. \cite{EC:CHKLM05} (henceforth \emph{UC-security}). Both definitions take pages to describe and explain, and contain various subtleties that are confusing to beginners and understudied by the community. A standard result \cite[Appendix~A]{EC:CHKLM05} shows that UC-security implies BPR-security.

Over the years, a large number of variants of both BPR- and UC-security have been proposed. While many of these are essentially tailoring the definition to fit a specific protocol construction, some do have an intuitive interpretation and capture certain nuances of PAKE security. This work focuses on two of them:
\begin{itemize}
  \item The variant of BPR-security by Katz, Ostrovsky and Yung \cite{JACM:KatOstYun09} (henceforth \emph{KOY-security}), which places more constraints on what exactly counts as an ``active online attack''; and
  \item The variant of UC-security by Dupont et al. \cite{EC:DHPRY18} called \emph{implicit-only UC-security}, which disallows the ideal adversary from learning whether an online attack has succeeded or not.
\end{itemize}
Neither of the aforementioned works' main focus was security notions. The conference proceedings version of the KOY paper \cite{EC:KatOstYun01} proposed a new PAKE protocol and proved its BPR-security; in the journal version \cite{JACM:KatOstYun09} KOY proved that their protocol actually satisfies the stronger KOY-security, although the difference between these two notions was left unexplained. Implicit-only UC-security was introduced because the authors of \cite{EC:DHPRY18} used PAKE to construct some higher-level protocols, and the underlying PAKE needs this stronger security notion for the higher-level protocol to be secure. Perhaps this explains why these two security notions are not widely used: we do not know of any studies of either KOY- or implicit-only UC-security per se, and subsequent works generally continued to use BPR- and UC-security.

\paragraph{Our contributions.}
In this work, we present a thorough study of KOY- and implicit-only UC-security for PAKE, and draw some interesting connections between them and their more standard counterparts. Our technical contributions are two-fold:
\begin{enumerate}
  \item In \Cref{sec:counterexample} we show that UC-security does \emph{not} imply KOY-security, by giving a concrete counterexample that is UC-secure but not KOY-secure;
  \item In \Cref{sec:implicit-only} we show that implicit-only UC-security implies KOY-security. Furthermore, by examining our proof, one can easily recover the standard proof that UC-security implies BPR-security.
\end{enumerate}
Finally, in \Cref{sec:conclusion} we point out that KOY- and implicit-only UC-security essentially strengthen their more standard counterparts in the same way, namely \emph{disallowing the adversary from learning whether an online attack has succeeded or not by merely examining the protocol transcript (without seeing the attacked party's output key)}. In this way, we give an interpretation of what exactly the KOY- and implicit-only UC-security notions entail.

As a side contribution, in \Cref{sec:prelims} we discuss the four security definitions in detail --- not only \emph{what} exactly these definitions do, but also the \emph{rationales} behind certain design choices in the definitions. By doing this, we hope to help ``demystify'' PAKE security notions and make them more friendly to beginners.

\paragraph{A personal anecdote: how did I dig out KOY-security?}
I learned game-based PAKE security definitions ``backwards''. For a very long time, KOY-security was the standard reference for me, and I had no idea that KOY and BPR were actually different. Very recently, I needed to prove a generalization of UC-security $\Rightarrow$ game-based security, and I just couldn't make the proof go through. After some thought, I realized that the ``theorem'' I tried to prove was actually wrong --- similar to the counterexample in \Cref{sec:counterexample} --- and you needed to tweak the game-based security definition to make the proof work.

At that time I thought there was an error in the standard result in \cite{EC:CHKLM05}. \cite{EC:CHKLM05} claims that their game-based security notion follows BPR, so I checked \cite{EC:BelPoiRog00}. I immediately realized that the ``BPR-security'' I had in mind was in fact not what BPR said, and the actual BPR-security was exactly what I needed in my proof.

I decided to write down my counterexample. During this process, I realized that apart from replacing KOY- with BPR-security, another way to invalidate the counterexample was to strengthen UC-security to implicit-only UC-security. Perhaps implicit-statement UC-security implies KOY-security? This proof indeed went through, and the technical pieces of this work were complete.

\section{Preliminaries}
\label{sec:prelims}
Let $\lambda$ be the security parameter. Most notations in this work are standard: for example, $x \gets S$ means sampling an element $x$ uniformly at random from set $S$; $x := a$ means assigning value $a$ to variable $x$; and PPT means ``probabilistic polynomial-time''. We assume the reader is familiar with the UC framework \cite{FOCS:Canetti01}.
\subsection{Overview of Security Definitions for PAKE}
We first give an informal, high-level overview of the ideas behind the security definitions for PAKE; what's said in this section applies to both the game-based and UC-security definitions.

Any reasonable security definition for PAKE must formalize the following two principles:
\begin{framed}
\begin{displayquote}
  \emph{The first principle: The adversary can only perform a single online guessing attack per protocol instance.}
  
  \emph{The second principle: All output keys are independent of each other, except in cases where correlation is inevitable.}
\end{displayquote}
\end{framed}
Correspondingly, the definition must contain the following parts (which is where the technical complications come from):
\begin{enumerate}
  \item What exactly constitutes an ``online guessing attack'' must be defined.
  \item Each protocol instance should output a uniformly random key independent of everything else, except that the cases where correlation is inevitable need to be singled out and handled separately. 
\end{enumerate}

The second principle warrants further explanation. What are those cases where correlation of output keys is inevitable? There are two of them:
\begin{itemize}
  \item If the adversary succeeds in an online attack, then of course it can learn the attacked instance's output key. In this case all security guarantees for this instance are lost and we cannot claim independence;
  \item If the adversary is passive between two instances (i.e., it merely forwards all protocol messages without any modification), then of course these two instances output the same key. (But this key should still be independent of other instances' output keys.)\footnote{This assumes that the two instances' passwords match. As we will see, in the game-based definitions we always assume this, whereas in the UC definitions we additionally consider the case where the two instances (that intend to connect to each other) hold different passwords.}
\end{itemize}

We will see that the above forms the core of both the game-based and UC definitions; however, they formalize these two principles in drastically different ways.
\subsection{BPR- And KOY-Security Definitions for PAKE}
\paragraph{Setup.}
The system consists of a number of protocol parties $P$, and each party can have a number of instances $P^i$. An instance can send protocol messages to an instance that belongs to another party.

Let $D$ be the set of all candidate passwords (the ``dictionary''); we assume $D$ has polynomial size. For each pair of instances $(P^i, (P')^j)$, sample $\pw_{i,j} = \pw_{j,i} \gets D$ as the shared password between them.\footnote{We write $P^i$ and $(P')^j$ to stress that if two instances want to communicate, they must belong to different parties. Both \cite{EC:BelPoiRog00} and \cite{JACM:KatOstYun09} partition all parties into two categories, clients and servers, and a client instance must communicate with a server instance (and vice versa). Our treatment is slightly more general (e.g., it allows Alice to be a client while talking to Bob and a server while talking to Carol).} (Note that we do not consider the case where the two instances hold different passwords.)

\paragraph{Protocol execution.}
The security notion for PAKE is formalized as a game between a PPT adversary $\adv$ and a game challenger, where the challenger runs the protocol parties (and their instances) and sends to $\adv$ certain information that $\adv$ is supposed to learn during an attack. Concretely, $\adv$ can send the following commands to the game challenger:
\begin{itemize}
  \item $\Execute(P^i, (P')^j)$ --- This models an eavesdropping attack, where the adversary is passive and learns all protocol messages sent between the two instances (the ``protocol transcript''). Concretely, if neither $P^i$ nor $(P)'^j$ is used, the game challenger runs the protocol between $P^i$ and $(P')^j$, and returns the transcript to $\adv$. Once a $\Execute(P^i, (P')^j)$ command is sent, the game challenger marks both $P^i$ and $(P')^j$ as used.
  \item $\Send(P^i, (P')^j, m^*)$ --- This models a man-in-the-middle attack, where the adversary sends message $m^*$ to $(P')^j$, as if the message is from $P^i$ (below we simply say ``the adversary sends message $m^*$ from $P^i$ to $(P')^j$''). Concretely, the game challenger sends message $m^*$ from $P^i$ to $(P')^j$; if $(P')^j$ sends a protocol message $m'$ then the game challenger returns $m'$ to $\adv$, otherwise (i.e., $m^*$ is the last message in the protocol causing $(P')^j$ to terminate) the game challenger returns $\bot$ to $\adv$. \\
      As a special case, $\Send(P^i, (P')^j, \text{start})$ models the adversary initiating instance $P^i$ and sees its first message (intended for $(P')^j$). Concretely, if $P^i$ is not used, the game challenger initiates instance $P^i$ and returns $P^i$'s message to $\adv$. Once a $\Send(P^i, (P')^j, \text{start})$ command is sent, the game challenger marks $P^i$ as used.\footnote{Our specification assumes that if $(P')^j$ is the responder, i.e., $(P')^j$ waits for $P^i$'s message before sending its own message, then $\Send((P')^j, P^i, \text{start})$ returns $\bot$ and $\Send(P^i, (P')^j, m^*)$ returns $(P')^j$'s message to $P^i$ only if a $\Send((P')^j, P^i, \text{start})$ command has been sent. (In other words, in order to see the responder's message, $\adv$ has to send both a ``start'' command and a $\Send$ command with the initiator's message.) This slightly deviates from \cite{EC:BelPoiRog00,JACM:KatOstYun09} but fits the UC-security definition better.}
\end{itemize}
Note that how we handle a used instance (i.e., an instance that has been initiated) guarantees that an instance cannot be run twice; in particular, $\adv$ cannot send both $\Execute$ and $\Send$ on the same instance. Therefore, all used instances can be partitioned into two types: $\Execute$ instances and $\Send$ instances.
\begin{itemize}
  \item $\Reveal(P^i)$ --- This models the adversary learning a completed instance's output key, via e.g., a side-channel attack. Concretely, if $P^i$ has computed its output key $K_i$, the game challenger returns $K_i$ to $\adv$; otherwise the game challenger returns $\bot$ to $\adv$.
\end{itemize}
\section{UC-Security Does Not Imply KOY-Security}
\label{sec:counterexample}
\subsection{The Counterexample}
Consider the following PAKE protocol:

\bigskip\noindent\textbf{\underline{Protocol $\Pi$}:}
\begin{enumerate}
  \item Protocol parties $P$ and $P'$ run EKE, resulting in keys $K$ (for $P$) and $K'$ (for $P'$).
  \item $P$ sends $h := H_0(K)$ to $P'$.
  \item $P$ and $P'$ outputs $H(K)$ and $H(K')$, respectively. Here, $H$ and $H_0$ are two ROs from $\{0,1\}^\lambda$ to itself.
\end{enumerate}
\begin{figure}[H]
\pseudocodeblock{
P(\pw) \< \< P'(\pw') \\ 
\< \sendmessagerightleft*{\text{EKE}} \< \\
K \< \< K' \\
\< \sendmessageright*{h := H_0(K)} \< \\
\text{output }H(K) \< \< \text{output }H(K')
}
\caption{Our counterexample}
\end{figure}
Note that $h$ is a redundant message, in the sense that neither party's output depends on it.
\subsection{The Protocol Is UC-Secure}
\begin{proof}
Since EKE is UC-secure, we may replace the EKE part in protocol $\Pi$ with the UC PAKE functionality $\Fpake$. Call the resulting protocol $\tilde{\Pi}$; we only need to prove that $\tilde{\Pi}$ is UC-secure. In order to distinguish the $\Fpake$ that is a building block of the \emph{real protocol} $\tilde{\Pi}$ and the $\Fpake$ that is the functionality interacting with the simulator in the \emph{ideal world}, we abbreviate the latter as $\func$.

Consider the following simulator $\sim$. Roughly speaking, $\sim$ simulates $\Fpake$ honestly, and samples a random string as $h$, unless $P$'s instance has been successfully attacked --- in which case $\sim$ knows $P$'s EKE key and can simulate $h$ honestly:

\bigskip\noindent\textbf{\underline{Simulator $\sim$}:}
\begin{enumerate}
  \item On $(\NewSession, sid, P, P')$ from $\func$, send the same message from $\Fpake$ to $\adv$. \\
      On $(\NewSession, sid, P', P)$ from $\func$, also send the same message from $\Fpake$ to $\adv$.
  \item On $(\TestPwd, sid, \star, \star)$ from $\adv$ to $\Fpake$, forward this message to $\func$ and sends $\func$'s responde from $\Fpake$ to $\adv$. This defines a state of $P$'s instance ($\fresh$, $\compromised$ or $\interrupted$).
  \item On $(\NewKey, sid, P, K^*)$ from $\adv$ to $\Fpake$,
      \begin{enumerate}[(i)]
        \item If there has been a $(\TestPwd, sid, P, \star)$ command from $\adv$ to $\Fpake$ which resulted in ``correct guess'' (see step 2), then set $h := H_0(K^*)$; otherwise sample $h \gets \{0,1\}^\lambda$. Either way, send $h$ from $P$ to $P'$.
        \item Also compute $SK^* := H(K^*)$ and send $(\NewKey, sid, P, SK^*)$ to $\func$.
      \end{enumerate}
  \item On $(\NewKey, sid, P', (K')^*)$ from $\adv$ to $\Fpake$ and $h^*$ from $\adv$ to $P'$, compute $(SK')^* := H((K')^*)$ and send $(\NewKey, sid, P', (SK')^*)$ to $\func$.
\end{enumerate}

We now show that for any environment $\env$, $\sim$ generates an ideal-world view that is indistinguishable from $\env$'s real-world view. Let $K$ and $K'$ be $P$ and $P'$'s EKE key, respectively, and $SK$ and $SK'$ be $P$ and $P'$'s final output key in $\tilde{\Pi}$, respectively. Define $\mathsf{QueryP}$ be the event that
\begin{itemize}
  \item $\adv$ does not send a $(\TestPwd, sid, P, \star)$ command resulting in ``correct guess'', but
  \item $\adv$ queries $H_0(K)$ or $H(K)$.
\end{itemize}
Define $\mathsf{QueryP'}$ be the event that
\begin{itemize}
  \item $\adv$ does not send a $(\TestPwd, sid, P', \star)$ command resulting in ``correct guess'', but
  \item $\adv$ queries $H(K)$.
\end{itemize}
\begin{claim}
$\Pr[\mathsf{QueryP}]$ and $\Pr[\mathsf{QueryP'}]$ are both negligible.
\end{claim}

If $\adv$ does not send a $(\TestPwd, sid, P, \star)$ command resulting in ``correct guess'', then $\Fpake$ marks $P$'s session as either $\fresh$ or $\interrupted$. Either way, when $K$ is generated it is a uniformly random string in $\{0,1\}^\lambda$ independent of $\env$'s view, and later the only information $\env$ learns about $K$ is $H_0(K)$ (from the protocol message) and $H(K)$ (from $P$'s output key) --- which are independent of $K$ unless and until $\mathsf{QueryP}$ happens. Therefore, $\Pr[\mathsf{QueryP}]$ is upper-bounded by $q_H/2^\lambda$ (where $q_H$ is the total number of $H$ and $H_0$ queries). A similar argument works for $\mathsf{QueryP'}$.
\begin{claim}
If neither $\Pr[\mathsf{QueryP}]$ nor $\Pr[\mathsf{QueryP'}]$ happens, then $\env$'s views in the real world and in the ideal world are identical.
\end{claim}
The argument goes as follows:
\begin{enumerate}
  \item Regarding $\adv$'s interface with $\Fpake$, $\sim$ does nothing other than forwarding $\adv$'s message to $\func$ and forwarding $\func$'s response back to $\adv$. In other words, $\sim$ simulates $\Fpake$ honestly. So $\sim$ generates a view that is identical to the real-world view.
  \item Regarding protocol message $h$, first note that in both worlds this message is generated right after $\adv$ sends $(\NewKey, sid, P, K^*)$ to $\Fpake$.
      \begin{itemize}
        \item If $\adv$ has sent a $(\TestPwd, sid, P, \star)$ command resulting in ``correct guess'', then in the real world $P$'s instance in $\func$ was $\compromised$. This causes $P$'s EKE key $K$ to be equal to $K^*$, so $h = H_0(K) = H_0(K^*)$. This exactly matches how $h$ is generated by $\sim$.
        \item Otherwise, we know that $\adv$ does not query $H_0(K)$ (because $\mathsf{QueryP}$ does not happen). This means that in the real world $h = H_0(K)$ is a uniformly random string in $\{0,1\}^\lambda$ independent of the rest of the game, which again matches how $h$ is generated by $\sim$.
      \end{itemize}
  \item Regarding $P$'s output key $SK$,
      \begin{itemize}
        \item If $\adv$ has sent a $(\TestPwd, sid, P, \star)$ command resulting in ``correct guess'', then as argued above, in the real world $K = K^*$, so $SK = H(K) = H(K^*)$. In the ideal world, $\sim$ computes $SK^* = H(K^*)$, so $SK^* = SK$. Furthermore, $\func$ has marked $P$'s instance $\compromised$ (because $\sim$ has sent a $(\TestPwd, sid, P, \star)$ command resulting in ``correct guess''), so when $\sim$ sends $(\NewKey, sid, P, SK^*)$ to $\func$, $\func$ outputs $SK^*$ to $P$. In sum, in both worlds $P$'s output key is $SK = H(K^*)$, so there is no difference.
        \item Otherwise, we know that $\adv$ does not query $H(K)$ (because $\mathsf{QueryP}$ does not happen). This means that in the real world $SK$ is a uniformly random string in $\{0,1\}^\lambda$ independent of the rest of the game. In the ideal world, $\func$ has marked $P$'s instance $\fresh$ or $\interrupted$, so when $\sim$ sends $(\NewKey, sid, P, SK^*)$ to $\func$, $\func$ ignores $SK^*$ and freshly samples a uniformly random string in $\{0,1\}^\lambda$ as $P$'s output key. In sum, in both worlds $P$'s output key is $SK \gets \{0,1\}^\lambda$, so there is no difference.
      \end{itemize}
      The same argument can be made for $P'$'s output key $SK'$.
\end{enumerate}

Combining the two claims above immediately yields the UC-security of $\tilde{\Pi}$.
\end{proof}
\subsection{The Protocol Is Not KOY-Secure}
\begin{proof}
Consider the following adversary $\adv$. Roughly speaking, $\adv$ assumes the role of $P'$ and runs $P'$'s algorithm on all candidate passwords, and uses $h$ to find out which one is the correct password (after which the attack becomes trivial):

\bigskip\noindent\textbf{\underline{Adversary $\adv$}:}

\medskip
For all $\pw_i \in D$, $\adv$ performs the following steps until it finds $\pw^*$:
\begin{enumerate}
  \item Initiate $P$'s instance $P^i$ by sending $\Send(P^i, \text{start})$ to the game challenger.
  \item On $c$ from the game challenger, sample $y \gets \Z_p$ and
      \begin{enumerate}[(i)]
        \item Compute $Y^* := \ICEnc(\pw_i, g^y)$ and send $\Send((P')^i, P^i, Y^*)$ to the game challenger.
        \item Also, compute $X := \ICDec(\pw_i, c)$ and then $K^* := X^y$.
      \end{enumerate}
  \item On $h$ from the game challenger, check if $h = H_0(K^*)$. If so, set $\pw^* := \pw_i$ and break the for-loop. Otherwise move on to the next element in $D$.
\end{enumerate}

See below for a graphic illustration of steps 1--3 of $\adv$.
\begin{figure}[H]
\pseudocodeblock{
P(\pw) \< \< \adv(\pw_i) \\ 
\< \sendmessagerightleft*{\text{EKE}} \< \\
K \< \< K^* \\
\< \sendmessageright*{h := H_0(K)} \< \\
\< \< h = H_0(K^*) \\
\< \< \text{if so, }\pw^* := \pw_i;\text{ break}
}
\end{figure}

After the for-loop ends, $\adv$ finds the $i$ such that $\pw^* = \pw_i$ and performs the following step:
\begin{enumerate}
\setcounter{enumi}{3}
  \item Send $\Test(P^i)$ to the game challenger. If the result is equal to $H(K^*)$, output 1; otherwise output 0.
\end{enumerate}

Note that {\color{blue}$\adv$ only sends a single $\Test$ command, so it only does 1 active session attack and its ``baseline'' winning probability is $1/2 + 1/2|D|$}. However, we show that $\adv$'s winning probability is in fact overwhelming:
\begin{claim}
The probability that $\pw^* = \pw$, i.e., $\adv$ finds the correct password, is overwhelming.
\end{claim}
Recall EKE has the property that the two parties' output keys are equal \emph{if and only if} their passwords match. Note that $\adv$'s steps 1--2 are exactly what an honest $P'$ would to on password $\pw_i$; therefore, if $\pw_i = \pw$ then $P$'s EKE key $K \neq K^*$, so $h = H_0(K)$ is not equal to $H_0(K^*)$ except with probability $1/2^\lambda$, causing $\adv$ to move on to the next candidate password. If $\pw_i = \pw$ then $P$'s EKE key $K = K^*$, so $h = H_0(K) = H_0(K')$, causing $\adv$ to break the for-loop and set $\pw^* := \pw_i = \pw$. Overall, $\adv$ sets $\pw^* = \pw$ except with probability up to $(|D|-1)/2^\lambda$.
\begin{claim}
If $\pw^* = \pw$, then $\adv$ wins with overwhelming probability.
\end{claim}
Suppose $b = 1$. Then when $\adv$ sends $\Test(P^i)$, the game challenger returns $P^i$'s output key $H(K)$. But if $\pw^* = \pw$ then $K^* = K$, so $H(K) = H(K^*)$ and $\adv$ outputs 1.

Now suppose $b = 0$. Then when $\adv$ sends $\Test(P^i)$, the game challenger returns a uniformly random string in $\{0,1\}^\lambda$ independent of the rest of the game. Therefore, $\adv$ outputs 1 with probability $1/2^\lambda$.

In sum, $\adv$ wins with probability 1 when $b = 1$ and $1-1/2^\lambda$ when $b = 0$. Its overall winning probability is $1-1/2^{\lambda+1}$.

\medskip
Combining the two claim above immediately yields that $\adv$ wins with overwhelming probability, so $\Pi$ is not KOY-secure.
\end{proof}
\paragraph{$\Pi$ is still BPR-secure.}
Our attack above does not violate the BPR-security of $\Pi$. This is because the sentence in blue does not hold anymore: $\adv$ sends up to $|D|$ $\Send$ commands, so in BPR the number of active attacks is up to $|D|$ and thus $\adv$'s ``baseline'' winning probability is $1/2 + |D|/2|D| = 1$.

\subsection{What Does This Entail?}
Where do things go wrong: is the UC-security notion too weak, or is the game-based security notion too strong?

The crux of the whole issue lies in how exactly an ``active attack'' is defined in the game-based security definition. There, an instance is said to be actively attacked \emph{only if there is \textbf{both} a $\Send$ command and a $\Test$ command} for this instance. In other words, if the adversary actively chooses protocol messages but does not see the attacked party's output key, then this doesn't count as an ``active attack''. However, our counterexample has the property that
\begin{displayquote}
\emph{The protocol transcript --- without the honest party's output key --- already leaks information about the password.}
\end{displayquote}
Therefore, the adversary can test a password guess --- and eventually find the correct password --- without sending a $\Test$ command (i.e., without an ``active attack''), violating game-based security.

On the other hand, this property is allowed by the UC-security notion. In fact this is even \emph{intended}: in the UC PAKE functionality active attacks are modeled by the $\TestPwd$ command, from which the ideal adversary can learn whether its password guess is correct or not. This is intended to model the scenario where \emph{the adversary learns whether its password guess is correct immediately after sending the protocol message that contains the password guess, without seeing the attacked party's output key}.

In other words, there is a mismatch between the two security notions regarding whether the adversary can learn whether its password guess is correct by looking at the protocol transcript only: the game-based security notion says ``no'', whereas the UC-security notion says ``yes''. Our counterexample exactly exploits this gap.

We argue that the UC-security notion is the more ``natural'' way of modeling PAKE security. Indeed, what we do in our counterexample --- sending an authenticator for the counterparty to check if the login attempt has been successful --- is exactly what's done to achieve explicit authentication in PAKE, i.e., the property above is common. (The uncommon thing in our counterexample is that the receiver does not actually verify the authenticator and outputs the intended output key anyway.) Therefore, in the game-based security definition a $\Send$ command alone --- which allows the adversary to see the protocol transcript --- should already be counted as an active attack.

\section{Implicit-Only UC-Security Implies KOY-Security}
\label{sec:implicit-only}
Our main result in this section is:
\begin{theorem}
Suppose $\Pi$ is a PAKE protocol that UC-realizes $\Fipake$. Then $\Pi$ is KOY-secure.
\end{theorem}
\begin{proof}
Consider any PPT adversary $\widehat{\adv}$ in the KOY-security game for $\Pi$, and let $q$ be the number of active attacks by $\widehat{\adv}$; we want to upper-bound $\widehat{\adv}$'s winning probability. (We use $\widehat{\adv}$ instead of $\adv$ to emphasize that it is the adversary in the game-based definition, not the UC adversary.) The outline of the proof is as follows:
\begin{enumerate}
  \item We first ``translate'' $\widehat{\adv}$ into a UC environment $\env$ that essentially does what $\widehat{\adv}$ does during protocol execution. $\env$ outputs 1 if and only if $\widehat{\adv}$ wins.
  \item Since $\env$ simulates the KOY-security game for $\widehat{\adv}$, the probability that $\env$ outputs 1 in the real world is equal to $\widehat{\adv}$'s winning probability.
  \item However, in the ideal world $\widehat{\adv}$'s winning probability is limited by how much it learns about the password. But $\widehat{\adv}$ gains some information about the password only if \emph{both} (1) the simulator does a successful online attack, and (2) $\widehat{\adv}$ sees the attacked instance's output key. The number of occurrences of (1) and (2) is exactly $q$.
  \item Therefore, $\widehat{\adv}$'s winning probability must be close to the ``baseline''.
\end{enumerate}
Steps 1 and 2 are essentially identical to the proof of UC-security $\Rightarrow$ BPR-security \cite{EC:CHKLM05}; the main technical challenge lies in step 3.
\paragraph{``Translating'' $\widehat{\adv}$ into a UC environment.}
Consider the following UC environment $\env$:

\bigskip\noindent\textbf{\underline{Environment $\env$}:}
\begin{enumerate}
\setcounter{enumi}{-1}
  \item Sample $b \gets \{0,1\}$ and invoke $\widehat{\adv}$.
  \item For each pair of instances $(P^i, (P')^j)$, sample a password $\pw_{i,j} = \pw_{j,i} \gets D$.
  \item On $\Execute(P^i, (P')^j)$ from $\widehat{\adv}$, pick a fresh $sid_{i,j} = sid_{j,i}$ and send $(\NewSession, sid_{i,j}, P', \pw_{i,j})$ to $P'$ and $(\NewSession, sid_{i,j}, P, \pw_{i,j})$ to $P$. (Below we may simply write $sid$ and $\pw$ when $i,j$ are clear from the context.) Then instruct the UC PAKE adversary $\adv$ to be passive in this session. After the session completes, provide $\widehat{\adv}$ with its transcript. (Note that $P^i$ is an instance in the KOY-security game simulated by $\env$, whereas $P$ is a UC protocol party that interacts with $\env$.)
  \item On $\Send(P^i, (P')^j, \text{start})$ from $\widehat{\adv}$, if there has been a $\Send((P')^j, P^i, \text{start})$ command, then $sid_{j,i} = sid_{i,j}$ must have been defined. In this case, send $(\NewSession, sid_{i,j}, P', \pw)$ to $P$. Otherwise pick a fresh $sid_{i,j} = sid_{j,i}$ and send $(\NewSession, sid_{i,j}, P', \pw)$ to $P$. \\
      On $\Send(P^i, (P')^j, m^*)$ from $\widehat{\adv}$, instruct the UC PAKE adversary $\adv$ to send a message $(sid, m^*)$ to $P'$. \\
      In all cases above, forward the message $\adv$ receives to $\widehat{\adv}$.
  \item On $\Reveal(P^i)$ from $\widehat{\adv}$, fetch $sid_{i,j}$ (where $j$ is the index of instance $(P')^j$ that $P^i$ communicates with). If $P$ has output $(sid_{i,j}, SK)$ to $\env$, return $SK$; otherwise return $\bot$.
  \item $\Test(P^i)$ from $\widehat{\adv}$ is handled in the same way as $\Reveal(P^i)$, except that ``return $SK$'' is replaced by ``return $SK$ if $b = 1$ and a random string in $\{0,1\}^\lambda$ if $b = 0$''.
  \item When $\widehat{\adv}$ outputs a bit $b^*$, output 1 if $b^* = b$ and 0 otherwise.
\end{enumerate}
\paragraph{Analysis in the real world.}
If $\env$ is in the real world, then it exactly simulates $\Pi$'s KOY-security game for $\widehat{\adv}$. We have 
\[
\Pr[\env\text{ outputs }1\text{ in the real world}] = \Pr[b^* = b\text{ in the real world}] = \Pr[\widehat{\adv}\text{ wins}].
\]
\paragraph{Analysis in the ideal world.}
Now suppose $\env$ is in the ideal world. Let $\sim$ be the simulator that generates a ideal-world view indistinguishable from $\env$'s real-world view. We now upper-bound $\Pr[b^* = b\text{ in the ideal world}]$.

Define ``bad event''
\begin{align*}
\CorrectGuess : \sim\text{ sends }(\TestPwd, sid_{i,j}, P, \pw)\text{ to }\Fipake \\
\text{where }\widehat{\adv}\text{ performs an active attack on }P^i,
\end{align*}
i.e., $\CorrectGuess$ happens if $\sim$ tests $\pw$ on an instance on which $\widehat{\adv}$ performs an active attack. (Intuitively, $\CorrectGuess$ happens if $\widehat{\adv}$'s protocol messages contain password guess $\pw$, which is extracted by $\sim$; and eventually $\widehat{\adv}$ learns this instance's output key.)
\begin{claim}
\label{clm:tested}
Suppose $\SpuriousGuess$ does not happen. Then $\Pr[\CorrectGuess] \leq \cfrac{q}{|D|}$.
\end{claim}
This claim is the crux of the entire proof (and where we crucially deviate from \cite{EC:CHKLM05}). The key point is to \emph{view $\widehat{\adv}$ and $\sim$ combined as a single entity, and see what information they receive about $\pw$}. In fact there is only a single cycle through which $\widehat{\adv}$ and $\sim$ might (jointly) learn some information about $\pw$:
\begin{enumerate}
  \item For a certain instance, $\sim$ submits a password guess $\pw^*$ (via $\TestPwd$) and a key $K^*$ (via $\NewKey$) to $\Fipake$.
  \item $\Fipake$ generates key $K$ which is equal to $K^*$ if $\pw^* = \pw$ and uniformly random otherwise. $\Fipake$ then sends $K$ to the UC protocol party $P$.
  \item $P$ forwards $K$ to $\env$.
  \item When $\widehat{\adv}$ sends a $\Reveal$ command for this instance, or a $\Test$ command in the case of $b = 1$, $\env$ returns $K$ to $\widehat{\adv}$.
\end{enumerate}
(Other information $\widehat{\adv}$ and $\sim$ may receive includes $\NewSession$ commands from $\Fipake$ to $\sim$, indicating that a session has begun. This message is of course independent of $\pw$. Note in particular that protocol messages $\widehat{\adv}$ receives on $\Execute$ and $\Send$ commands are in fact simulated by $\sim$: upon receiving such a command, $\env$ lets $\sim$ simulate protocol messages for the UC PAKE adversary $\adv$, which $\env$ forwards to $\widehat{\adv}$. Therefore, {\color{blue}when we view $\widehat{\adv}$ and $\sim$ jointly, $\Execute$ and $\Send$ commands (without $\Reveal$ or $\Test$) provide no information about $\pw$}.)

Let's call steps 1--4 above a ``cycle''. In short, the game becomes: in each cycle $\{\widehat{\adv}, \sim\}$ may specify $\pw^* \in D$ and $K^*$, and receive $K^*$ if $\pw^* = \pw$ and a uniformly random $K$ otherwise. $\CorrectGuess$ is triggered when $\{\widehat{\adv}, \sim\}$ specifies $\pw$. In each cycle the only information $\{\widehat{\adv}, \sim\}$ learns about $\pw$ is whether $\pw^* = \pw$, so $\Pr[\CorrectGuess]$ is upper-bounded by $\text{(number of cycles)}/|D|$.

How many cycles can $\{\widehat{\adv}, \sim\}$ complete? First, $\widehat{\adv}$ must send a $\Reveal$ or a $\Test$ command on this instance (otherwise $\{\widehat{\adv}, \sim\}$ does not learn $K$ and thus learns no information about $\pw$). Second, if $\SpuriousGuess$ does not happen then this session must be a $\Send$ session (otherwise $\sim$ does not even send a $\TestPwd$ command, i.e., $\{\widehat{\adv}, \sim\}$ does not even specify $\pw^*$). But a cycle that satisfies these conditions is exactly an active attack. Therefore, the number of cycles is at most $q$.

We conclude that
\[
\Pr[\CorrectGuess] \leq \frac{\text{number of cycles}}{|D|} \leq \frac{q}{|D|}.
\]
\begin{claim}
Suppose again $\SpuriousGuess$ does not happen. If $\CorrectGuess$ also does not happen, then $b^* = b$ with probability $1/2$.
\end{claim}
Consider the instance for which $\widehat{\adv}$ sends $\Test$. If it is an $\Execute$ instance, then $\sim$ does not send $\TestPwd$ (because $\SpuriousGuess$ does not happen), so this session is $\fresh$ and outputs a uniformly random key. If it is a $\Send$ instance, then this instance is actively attacked, so $\sim$ does not send $\TestPwd$ on the correct password (because $\CorrectGuess$ does not happen), so this session is $\fresh$ or $\interrupted$ and outputs a uniformly random key. This means that $b$ is independent of $\widehat{\adv}$'s view, so $\Pr[b^* = b] = 1/2$.

\medskip
Combining the two claims above, we get
\begin{align*}
&\Pr[\env\text{ outputs }1\text{ in the real world}] \\
\leq& \Pr[\CorrectGuess \mid \overline{\SpuriousGuess}] + \Pr[b^* = b \land \overline{\CorrectGuess} \mid \overline{\SpuriousGuess}] + \Pr[\SpuriousGuess] \\
\leq& \Pr[\CorrectGuess \mid \overline{\SpuriousGuess}] + \frac{1}{2}(1 - \Pr[\CorrectGuess \mid \overline{\SpuriousGuess}]) + \Pr[\SpuriousGuess] \\
=& \frac{1}{2} + \frac{1}{2}\Pr[\CorrectGuess \mid \overline{\SpuriousGuess}] + \Pr[\SpuriousGuess] \\
\leq& \frac{1}{2} + \frac{q}{2|D|} + \Pr[\SpuriousGuess] \\
\leq& \frac{1}{2} + \frac{q}{2|D|} + \negl,
\end{align*}
where the last inequality is due to \Cref{lem:spuriousguess}.
\paragraph{Putting it together.}
In sum, $\env$'s distinguishing advantage is at least
\[
\Pr[\widehat{\adv}\text{ wins}] - \frac{1}{2} - \frac{q}{2|D|} - \negl,
\]
which is negligible since $\Pi$ UC-realizes $\Fipake$. So
\[
\Pr[\widehat{\adv}\text{ wins}] \geq \frac{1}{2} + \frac{q}{2|D|} + \negl,
\]
completing the proof.
\end{proof}
\paragraph{Recovering the UC-security $\Rightarrow$ BPR-security proof.} One might ask where the proof breaks down if $\Pi$ only realizes $\Fpake$. The reason is that the statement in blue does not hold anymore, as there is another cycle that allows the combination of $\widehat{\adv}$ and $\sim$ to learn some information about $\pw$:
\begin{enumerate}
  \item For a certain instance, $\sim$ submits a password guess $\pw^*$ (via $\TestPwd$) to $\Fpake$.
  \item $\Fpake$ returns ``correct/wrong guess'' to $\sim$.
\end{enumerate}
Crucially, this cycle does not require $\widehat{\adv}$ to send $\Reveal$ or $\Test$, i.e., $\sim$ can ``help'' $\widehat{\adv}$ gain some information about $\pw$ without $\widehat{\adv}$ performing an active attack (per the KOY notion). This is exactly what our counterexample in \Cref{sec:counterexample} exploits.

On the other hand, if we take the BPR notion (where a $\Send$ command already counts as an active attack), then the cycle above still requires an active attack (assuming $\SpuriousGuess$ does not happen) and the rest of the proof still goes through. In this way we recover the security proof of UC-security $\Rightarrow$ BPR-security \cite{EC:CHKLM05}.

\bibliographystyle{alpha}
\bibliography{bib.bib}
\end{document}